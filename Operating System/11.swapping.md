# Virtual Memory Swapping

## Swapping

컴퓨터 시스템의 물리적 메모리는 한정되어 있다. 여러 프로세스가 동시에 실행되거나 하나의 프로세스가 매우 큰 메모리 공간을 요구할 때, 물리적 메모리만으로는 이를 모두 수용할 수 없다.

- **스와핑**은 물리적 메모리가 부족할 때 프로세스를 지원하는 중요한 메커니즘이다. 
  - 사용자 프로그램은 물리적 메모리의 양에 독립적이어야 한다.
  - 단일 프로세스가 매우 큰 주소 공간을 가질 수 있다. 일부 프로그램(e.g. 데이터베이스)은 실행 중에 매우 큰 공간을 요구할 수 있다. 
  - 여러 프로세스가 동시에 실행될 때, 각 프로세스의 메모리 요구량을 합치면 물리적 메모리를 초과할 수 있다.
- 물리 메모리를 디스크의 캐시처럼 생각할 수 있다.
  - 프로세스 내 참조 지역성을 활용한다. 대부분의 프로그램은 특정 시간에 메모리의 일부만을 집중적으로 사용한느데, 이를 참조 지역성(locality of reference)라고 한다. 이러한 특성을 활용해 자주 사용되지 않는 메모리 부분을 디스크로 스와핑할 수 있다.
  - 프로세스는 한 번에 주소 공간의 일부만 사용한다. 
  - 주소 공간의 일부만 물리 메모리에 있으면 된다.
  - 나머지는 디스크에 저장한다. 

### Memory Hierarchy

각 레이어는 위 레이어의 "backing store"의 역할을 한다.

<img width="501" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/2b0b25d4-5ff6-482d-8d52-7ef72953c041">

### How to Swap

1. **Memory Overlay**
    - 옛날 시스템에서는 메모리 오버레이를 사용했다. 
    - 프로그래머가 코드를 작성할 때, 필요한 코드나 데이터를 메모리로 이동시키거나 제거하는 작업을 수동을 관리했다.
    - 이 방식은 운영체제의 특별한 지원이 필요 없다.
    - MS-DOS와 같은 초기 운영 체제에서는 메모리 보호 기능이 없었기 때문에 메모리 오버레이를 사용하여 제한된 메모리에서 더 큰 프로그램을 실행할 수 있었다.
2. **Process-level swapping**
    - 이 방법에서는 프로세스 전체를 메모리에서 디스크로 이동시키거나 디스크에서 메모리로 다시 불러오는 방식으로 관리한다.
    - 메모리가 부족할 때, 전체 프로세스를 메모리에서 제거하고 디스크의 백업 저장소(백킹 스토어)에 저장한다.(swap-out)
    - 필요할 때, 이전에 스와핑 아웃된 프로세스를 다시 메모리로 불러와 실행을 재개한다.(swap-in)
3. **Page-level Swapping**
    - 프로세스 전체를 이동하는 대신 **메모리 페이지 단위**로 이동한다. 
    - 메모리의 사용되지 않는 특정 페이지를 디스크로 이동시켜 물리적 메모리를 해제한다.(swap-out or page-out)
    - 필요할 때 디스크에서 해당 페이지를 다시 메모리로 불러온다.(swap-in or page-in)

### Page-level Swapping

페이지 테이블 엔트리(PTE)는 가상 메모리 시스템에서 각 페이지에 대한 정보를 저장하는 데이터 구조이다. Present bit가 1일 때는 물리적 메모리에 존재함을 나타내고, 0일 때는 물리적 메모리에 존재하지 않고 디스크에 스와핑되어 있음을 나타낸다.하드웨어가 메모리 접근 시 PTE를 확인할 때, 현재 비트가 0인 경우 해당 페이지는 물리적 메모리에 존재하지 않으며, 이로 인해 **페이지 폴트**가 발생한다.

- **Page fault**
  - CPU가 접근하려는 페이지가 물리적 메모리에 없을 때 발생하는 이벤트이다. 
  - 페이지가 디스크에 스와핑되어 있을 때, OS는 페이지 퐅트를 해결하기 위해 페이지를 다시 메모리로 스와핑해야 한다. 
- **Page replacement**
  - 페이지 교체는 메모리에 새로운 페이지를 불러오기 위해 기존 페이지를 디스크로 내보내는 과정이다.
  - 새로운 페이지를 메모리에 불러오기 위해 기존 페이지를 디스크로 내보내는 공간 확보 작업이 필요하다. 

### Where to Swap

가상 메모리 시스템에서 스와핑할 때, 메모리 페이지를 어디에 저장할 것인지에 대한 두 가지 주요 옵션이 있다 : 파일 시스템 , 스왑 공간

- **File system**
  - 파일 시스템은 운영 체제에서 파일과 데이터를 저장하고 관리하는 영역이다. 스와핑 시, 파일 시스템을 사용하여 메모리 페이지를 디스크에 저장할 수 있다. 
  - 실행 파일(코드 & 데이터)등의 파일 형태로 메모리 페이지를 저장한다. 
- **Swap space**
  - 스왑 공간은 페이지 교체를 위해 예약된 디스크의 특정 부분이다.  이는 물리적 메모리와 디스크 간의 임시 저장소 역할을 한다.
  - 스왑 공간의 크기는 사용할 수 있는 메모리 페이지의 최대 수를 결정한다.
  - 스왑 공간은 전용 디스크 파티션으로 구성될 수도 있고, 파일 시스템의 파일로도 구성될 수 있다. 

<img width="499" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/b7d1e13f-8fe3-4bda-ba8c-fd31a9739e33">

### When to Swap

- Lazy approach
  - OS는 메모리 전체가 꽉 찰 때까지 기다렸다가, 다른 페이지를 위한 공간을 만들기 위해 페이지 교체를 하는 방법이다.
  - 이 방법은 비현실적이다.
- Based on threshold
  - OS는 메모리의 일정 부분은 비워두고 싶다.
  - 2개의 기준값이 있다 : HW(high watermark), LW(low watermark)
  - swap daemon 이라고 불리는 백그라운드 스레드는 메모리의 공간을 비우는 책임이 있다.(Linux 에서 `kswapd`)
    - 만약 (# free pages < LW) 이면 스왑 데몬은 물리 메모리에서 페이지들을 쫓아낸다.
    - 만약 (# free pages > HW) 이면, 스왑 데몬은 sleep 한다.  

<img width="485" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/d87ffcff-7e04-4e8e-816b-85891c38f841">

### What to Swap

각 페이지 프레임의 종류마다 교체 후보가 되었을 때 나타내는 반응이다.

- Not swapped (swap out의 대상이 아님)
  - Kernel code, Kernel data, Page tables for user processes, kernel stack for user processes
- Dropped(디스크에 쓰지 않음, read-only)
  - User code pages
- Dropped or swapped(clean 이면 drop, dirty면 swapped)
  - User data pages
- Swapped
  - User heap/stack pages
- Dropped or go to file system
  - Files mmap'ed to user processes, Page cache pages

## Page replacement policy

페이지 교체 정책의 목표는 페이지 폴트 발생률(miss rate)을 최소화하는 것이다.

- 미스 페널티(디스크에 접근하는 것)가 너무 높다. (> $\times 100,000$)
- 작은 미스 레이트가 전체적인 AMAT를 압도한다.

$AMAT = (P_{Hit} * T_M) + (P_{Miss} * T_{D})$

|인자|뜻|
|---|--|
|$T_M$|메모리에 접근하는 비용|
|$T_D$|디스크에 접근하는 비용|
|$P_{Hit}$|캐시에서 데이터를 찾을 확률(hit)|
|$P_{Miss}$|캐시에서 데이터를 못 찾을 확률(miss)|

### OPT (MIN)

- Belady's optimal replacement policy
  - 미래에 가장 덜 사용될 법한 페이지를 교체하자.
  - 가장 적은 페이지 폴트 발생률을 보인다.
  - 그렇지만 미래를 예측해야 한다.
  - 따라서 실용적이지는 않지만, 비교를 위해서 쓰인다. 

<img width="536" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/dfecd70e-c248-4b9d-b708-cd301dc50368">

### FIFO

- FIFO는 메모리에 가장 오래 있던 페이지를 교체하는 방법이다. 
- 구현하기 가장 쉽고, 간단하며, 모든 페이지가 동일한 시간을 보장받는다. 
- 그러나 FIFO 는 "Belady's anomaly" 문제가 있다. 이 문제는, 메모리의 사이즈가 커져도 페이지 폴트 발생 비율이 증가하는 것이다.

<img width="534" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/977acd45-62b0-4f16-b8c8-e2e0ccf116da">

### LRU

- LRU
  - LRU는 가장 예전에 접근되었던 페이지를 교체하는 방법이다. 즉 과거를 이용해서 미래를 예측한다.
  - 지역성이 있으면, LRU는 OPT에 근접한다. 
  - 스택 알고리즘은 Belady's anomaly 문제가 발생하지 않는다.
  - 어떤 페이지가 접근되었는지 관리해야 하기 때문에 구현하기 더 어렵다. 
  - 그러나 LRU는 페이지 접근 빈도수를 고려하지 않는다. (cf. LFU : Least Frequently Used)
  - 따라서 모든 워크로드를 잘 다루지는 않는다. 

- 스택 알고리즘
  - 메모리 사이즈를 증가시켜도 페이지 폴트 발생률이 커지지 않도록 하는 정책이다.
  - 메모리에 m개의 프레임이 있을 때 사용 중인 모든 페이지는 m+1개의 프레임에서도 사용된다.

<img width="526" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/1884edc5-327c-4f47-9f58-60dc8d600427">

### RANDOM

- 랜덤 페이지를 골라서 교체한다.
- 구현하기 아주 쉽다.
- 뽑는 것에 따라 성능이 좌우된다. 그렇지만 어떤 워크로드에서는 FIFO와 LRU의 성능보다 좋다. 

<img width="559" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/ff09ab5e-7020-439d-9741-6a8e9c449dc7">

### Comparisons

<img width="725" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/26b1370a-2838-4947-92b4-05f64fcba633">

### Implementing LRU

- 소프트웨어 접근
  - OS가 접근된 시간에 따라 페이지 프레임의 리스트를 관리한다.
  - 페이지가 접근되었으면 : 페이지를 리스트의 맨 앞으로 옮긴다.
  - 교체되어야할 페이지를 고를 때 : 리스트의 맨 뒤에 있는 페이지를 고른다.
  - 메모리 접근 시에는 속도가 느리지만, 교체할 떄는 빠르다. 
- 하드웨어 접근
  - 페이지 프레임 내에 타임스탬프 레지스터를 연결한다.
  - 페이지가 접근되면, 레지스터에 시스템 시간을 저장한다.
  - 교체되어야할 페이지를 고를 때 : 레지스터를 뒤져서 가장 과거에 접근된 레지스터를 찾는다.
  - 메모리 접근 시에는 빠르지만, 교체시에는 느리다.

### Clock

Clock 은 LRU와 근사하게 구현한 알고리즘이다.

- PTE에 R(Reference) bit을 사용한다.
  - 가상 페이지가 접근되었을 때, 하드웨어가 reference bit을 세팅한다.
- 모든 물리적 프레임을 원형으로 배열하여 각 프레임을 시계의 숫자처럼 나열한다.
- 교체할 대상을 찾기 위해 클럭 핸드를 사용한다.
  - 페이지 폴트가 발생하면, 핸드가 포인팅하고 있는 페이지는 검사된다.
  - R 비트가 1인 경우 :
    - 참조 비트가 1이면, 이는 최근에 사용된 페이지를 의미한다.
    - 참조 비트를 0으로 설정하고, 시계 바늘을 다음 페이지로 이동한다.
    - 이 과정을 'Second Chance' 알고리즘이라고도 하며, 페이지에게 두 번째 기회를 주는 것이다.
  - R 비트가 0인 경우 :
    - 참조 비트가 0이면, 이는 최근에 사용되지 않은 페이지를 의미한다.
    - 이 페이지를 교체 대상으로 선택하고, 새 페이지를 로드한다.
  - 페이지가 필요할 때마다 바늘은 다음 페이지로 빠르게 이동하여 참조 비트를 검사한다.
- 메모리가 클수록 시계 바늘이 모든 페이지를 검사하는 데 시간이 오래 걸린다. 이로 인해 참조 비트가 정확하게 최근 사용 여부를 반영하지 못할 수 있다. 모든 페이지가 참조 비트가 1로 설정된 경우, 시계 바늘이 한 바퀴를 돌아 다시 처음 페이지로 돌아와야 한다. 이로 인해 정보의 정확성이 떨어질 수 있다.

#### Clock Extensions

- Clustering : 페이지들을 모아서 한번에 내쫓기
  - 개별 페이지를 교체할 때마다 교체 알고리즘을 실행하는 것은 비용이 많이 든다. 
  - 디스크에 한 번에 많은 데이터를 쓰는 것이 여러 번 작은 데이터를 쓰는 것보다 더 효율적이다.
- M(modify) bit를 사용해서 dirty 의 여부에 따라 우선순위를 부여한다. 
  - dirty page 를 교체하는데는 비용이 많이 든다.
  - 참조 비트(R)가 0이고 수정 비트(M)도 0인 페이지는 최근에 사용되지 않았으며 수정되지 않은 페이지인다. 이러한 페이지부터 교체한다. 
- 각 페이지 프레밈마다 소프트웨어 카운터를 추가한다.
  - 소프트웨어 카운터는 페이지 프레임이 얼마나 오랫동안 사용되지 않았는지를 추적하는 데 사용된다. 이를 통해 페이지의 사용 패턴을 더 세밀하게 파악할 수 있다.
  - 페이지가 참조되지 않을 때(R 비트가 0), 해당 페이지의 카운터를 증가시킨다. 이렇게 하면 페이지가 얼마나 오랫동안 참조되지 않았는지를 나타낼 수 있다.
  - 작은 카운터 값은 페이지가 최근에 참조되었음을 의미한다.
  - 카운터 값이 특정 리밋을 초과하면, 페이지를 교체한다.

### Prefetching

OS는 페이지가 곧 사용될 것이라는 것을 예측하고, 미리 가져오는 것을 **prefetching** 이라 한다.

<img width="389" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/3f7cb9a0-59f0-4192-b9a3-647cca3fd03a">

### Clustering, Grouping

그룹을 지어서 한꺼번에 디스크에 write 를 하면, 개별적으로 write 하는 것보다 효율적이다. 

<img width="335" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/567a3ce6-e887-4a8e-9cd8-db0045dfde34">

### Thrashing

**스래싱(Thrashing)**은 가상 메모리 시스템에서 발생할 수 있는 심각한 성능 저하 현상이다. 이는 OS가 페이지 폴트를 처리하는 데 대부분의 시간을 소비하여 실제 작업을 거의 하지 못하는 상황을 말한다.

메모리가 oversubscribed 되었고, 실행 중인 프로세스가 필요한 메모리가 물리적 메모리의 용량을 넘어서는 것이다. 즉, 물리 메모리가 프로세스들의 "working sets"를 저장할 수 없는 것이다. working set 이란, 프로세스가 적극적으로 사용중인 페이지의 집합이다.

해결할 수 있는 방법으로는, 1) 프로세스 죽이기, 2) 메모리를 더 늘리기 가 있다. 

<img width="368" alt="image" src="https://github.com/ddoddii/OS-CA-Study/assets/95014836/32c8dc9b-adb2-4c55-a3f2-01e5931dc259">

## Summary

- VM mechanisms
  - Physical & Virtual addressing
  - Partitioning, segmentation, paging
  - Page table management, TLBs
- VM policies
  - Page replacement policy, page allocation policy
- VM optimizations
  - Demand paging, copy-on-write (space)
  - Multi-level page tables (space)
  - Efficient translation using TLBs (time)
  - Page replacement policy (time)
